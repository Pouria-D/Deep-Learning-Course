{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["kTXaq54a43D_"],"toc_visible":true,"authorship_tag":"ABX9TyP3+3bWQBaKR5Rc/9BVywgI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["HW3 - Q2\n","\n","Pouria Dadkhah 401201381"],"metadata":{"id":"TZbHVfnL5IaO"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OhLzYfSzK00N","executionInfo":{"status":"ok","timestamp":1703141961577,"user_tz":-210,"elapsed":24673,"user":{"displayName":"Pouria Dadkhah","userId":"05533946863193468432"}},"outputId":"bf185689-2b75-4489-e3f1-ea1a86b9d58b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["# Analysis of COCO Dataset"],"metadata":{"id":"kTXaq54a43D_"}},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torchvision.datasets.utils import download_and_extract_archive\n","import torch\n","\n","# Set the path to store the dataset locally in Colab\n","local_data_path = '/content/gdrive/MyDrive/Deep Learning/DL_HW3/coco_subset'\n","\n","# Download annotations file (instances_trainval2017.json)\n","download_and_extract_archive(\n","    url='http://images.cocodataset.org/annotations/annotations_trainval2017.zip',\n","    download_root=local_data_path,\n","    filename='annotations_trainval2017.zip'\n",")\n","\n","# Define the data transformations (resize, normalization, etc.)\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # Resize images to a common size\n","    transforms.ToTensor(),           # Convert images to tensors\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images\n","])\n","\n","# Download images (train2017 and val2017)\n","train_dataset = datasets.CocoDetection(\n","    root=local_data_path,\n","    annFile=f'{local_data_path}/annotations/instances_train2017.json',\n","    transform=transform\n",")\n","\n","test_dataset = datasets.CocoDetection(\n","    root=local_data_path,\n","    annFile=f'{local_data_path}/annotations/instances_val2017.json',\n","    transform=transform\n",")\n","\n","# Load subsets of the data (e.g., first 1000 images for training and first 500 images for testing)\n","train_subset = torch.utils.data.Subset(train_dataset, range(1000))\n","test_subset = torch.utils.data.Subset(test_dataset, range(500))\n","\n","# Create data loaders\n","batch_size = 32\n","train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4)\n","test_loader = torch.utils.data.DataLoader(test_subset, batch_size=batch_size, shuffle=False, num_workers=4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2CiU8sVyVwW","executionInfo":{"status":"ok","timestamp":1703143923662,"user_tz":-210,"elapsed":62205,"user":{"displayName":"Pouria Dadkhah","userId":"05533946863193468432"}},"outputId":"0a6dd1ad-ec57-488f-f1d8-c2c15693d284"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://images.cocodataset.org/annotations/annotations_trainval2017.zip to /content/gdrive/MyDrive/Deep Learning/DL_HW3/coco_subset/annotations_trainval2017.zip\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 252907541/252907541 [00:17<00:00, 14159801.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /content/gdrive/MyDrive/Deep Learning/DL_HW3/coco_subset/annotations_trainval2017.zip to /content/gdrive/MyDrive/Deep Learning/DL_HW3/coco_subset\n","loading annotations into memory...\n","Done (t=27.21s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.59s)\n","creating index...\n","index created!\n"]}]},{"cell_type":"code","source":["# Explore the dataset\n","print(\"Number of training images:\", len(train_dataset))\n","print(\"Number of test images:\", len(test_dataset))\n","\n","# Print class labels\n","print(\"Class Labels:\")\n","print(train_dataset.coco.cats)\n","\n","# Check the number of classes\n","num_classes = len(train_dataset.coco.cats)\n","print(\"Number of Classes:\", num_classes)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBG0VSjCMxiD","executionInfo":{"status":"ok","timestamp":1703143947359,"user_tz":-210,"elapsed":462,"user":{"displayName":"Pouria Dadkhah","userId":"05533946863193468432"}},"outputId":"c6bd244b-5955-448b-b6c9-2a19df92d907"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training images: 118287\n","Number of test images: 5000\n","Class Labels:\n","{1: {'supercategory': 'person', 'id': 1, 'name': 'person'}, 2: {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'}, 3: {'supercategory': 'vehicle', 'id': 3, 'name': 'car'}, 4: {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'}, 5: {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'}, 6: {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'}, 7: {'supercategory': 'vehicle', 'id': 7, 'name': 'train'}, 8: {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'}, 9: {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'}, 10: {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'}, 11: {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'}, 13: {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'}, 14: {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'}, 15: {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'}, 16: {'supercategory': 'animal', 'id': 16, 'name': 'bird'}, 17: {'supercategory': 'animal', 'id': 17, 'name': 'cat'}, 18: {'supercategory': 'animal', 'id': 18, 'name': 'dog'}, 19: {'supercategory': 'animal', 'id': 19, 'name': 'horse'}, 20: {'supercategory': 'animal', 'id': 20, 'name': 'sheep'}, 21: {'supercategory': 'animal', 'id': 21, 'name': 'cow'}, 22: {'supercategory': 'animal', 'id': 22, 'name': 'elephant'}, 23: {'supercategory': 'animal', 'id': 23, 'name': 'bear'}, 24: {'supercategory': 'animal', 'id': 24, 'name': 'zebra'}, 25: {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'}, 27: {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'}, 28: {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'}, 31: {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'}, 32: {'supercategory': 'accessory', 'id': 32, 'name': 'tie'}, 33: {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'}, 34: {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'}, 35: {'supercategory': 'sports', 'id': 35, 'name': 'skis'}, 36: {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'}, 37: {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'}, 38: {'supercategory': 'sports', 'id': 38, 'name': 'kite'}, 39: {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'}, 40: {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'}, 41: {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'}, 42: {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'}, 43: {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'}, 44: {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'}, 46: {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'}, 47: {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'}, 48: {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'}, 49: {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'}, 50: {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'}, 51: {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'}, 52: {'supercategory': 'food', 'id': 52, 'name': 'banana'}, 53: {'supercategory': 'food', 'id': 53, 'name': 'apple'}, 54: {'supercategory': 'food', 'id': 54, 'name': 'sandwich'}, 55: {'supercategory': 'food', 'id': 55, 'name': 'orange'}, 56: {'supercategory': 'food', 'id': 56, 'name': 'broccoli'}, 57: {'supercategory': 'food', 'id': 57, 'name': 'carrot'}, 58: {'supercategory': 'food', 'id': 58, 'name': 'hot dog'}, 59: {'supercategory': 'food', 'id': 59, 'name': 'pizza'}, 60: {'supercategory': 'food', 'id': 60, 'name': 'donut'}, 61: {'supercategory': 'food', 'id': 61, 'name': 'cake'}, 62: {'supercategory': 'furniture', 'id': 62, 'name': 'chair'}, 63: {'supercategory': 'furniture', 'id': 63, 'name': 'couch'}, 64: {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'}, 65: {'supercategory': 'furniture', 'id': 65, 'name': 'bed'}, 67: {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'}, 70: {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'}, 72: {'supercategory': 'electronic', 'id': 72, 'name': 'tv'}, 73: {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'}, 74: {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'}, 75: {'supercategory': 'electronic', 'id': 75, 'name': 'remote'}, 76: {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'}, 77: {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'}, 78: {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'}, 79: {'supercategory': 'appliance', 'id': 79, 'name': 'oven'}, 80: {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'}, 81: {'supercategory': 'appliance', 'id': 81, 'name': 'sink'}, 82: {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'}, 84: {'supercategory': 'indoor', 'id': 84, 'name': 'book'}, 85: {'supercategory': 'indoor', 'id': 85, 'name': 'clock'}, 86: {'supercategory': 'indoor', 'id': 86, 'name': 'vase'}, 87: {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'}, 88: {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'}, 89: {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'}, 90: {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}}\n","Number of Classes: 80\n"]}]},{"cell_type":"markdown","source":["# Data preproccessing Cifar10\n","\n","after analysisng the coco dataset and lack of time decided to use cifar10 for our experiment to avoide new challanges :)"],"metadata":{"id":"o7-_JUdw5ko8"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","# Step 1: Load the CIFAR-10 dataset\n","transform = transforms.Compose([#transforms.Resize((224, 224)),  # Resize images to a common size\n","                                transforms.ToTensor(),\n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n","\n","# Check the size of the datasets\n","print(f\"Training dataset size: {len(train_dataset)}\")\n","print(f\"Testing dataset size: {len(test_dataset)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3RbhNrMZZiLd","executionInfo":{"status":"ok","timestamp":1703149706935,"user_tz":-210,"elapsed":16561,"user":{"displayName":"Pouria Dadkhah","userId":"05533946863193468432"}},"outputId":"d3ba3eb1-cd00-4ed2-b3d9-60d1cb3a580f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:03<00:00, 44603620.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n","Training dataset size: 50000\n","Testing dataset size: 10000\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Function to show an image\n","def imshow(img):\n","    img = img / 2 + 0.5     # Unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","# Get a batch of training data\n","dataiter = iter(train_loader)\n","images, labels = next(dataiter)\n","\n","# Visualize a sample image and label from the batch\n","imshow(torchvision.utils.make_grid(images[:4]))\n","print(' '.join('%5s' % train_dataset.classes[labels[j]] for j in range(4)))\n","\n","# Number of classes in the dataset\n","num_classes = len(train_dataset.classes)\n","print(f\"\\nNumber of classes in the training dataset: {num_classes}\")\n","\n","# Number of classes in the test dataset\n","num_classes_test = len(test_dataset.classes)\n","print(f\"Number of classes in the test dataset: {num_classes_test}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"id":"2sCSAqB1Z7gd","executionInfo":{"status":"ok","timestamp":1703149712908,"user_tz":-210,"elapsed":887,"user":{"displayName":"Pouria Dadkhah","userId":"05533946863193468432"}},"outputId":"3903fd8a-1512-4b12-d0e3-82074de5642c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" deer  bird   cat  deer\n","\n","Number of classes in the training dataset: 10\n","Number of classes in the test dataset: 10\n"]}]},{"cell_type":"markdown","source":["# Models (CNN and DCN)"],"metadata":{"id":"DbLbuE3NNS6q"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","# Define a simple CNN model\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n","        self.fc2 = nn.Linear(512, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 128 * 8 * 8)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Instantiate the model, loss function, and optimizer\n","simple_cnn = SimpleCNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(simple_cnn.parameters(), lr=0.01, momentum=0.9)\n","\n","# Training the CNN\n","num_epochs = 10\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","simple_cnn.to(device)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n","\n","for epoch in range(num_epochs):\n","    simple_cnn.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","\n","    for data in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = simple_cnn(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","        _, predicted = outputs.max(1)\n","        total_train += labels.size(0)\n","        correct_train += predicted.eq(labels).sum().item()\n","\n","    train_accuracy = 100 * correct_train / total_train\n","    print(f'Training Loss: {running_loss / len(train_loader):.4f}, Training Accuracy: {train_accuracy:.2f}%')\n","\n","    # Validation on the test set\n","    simple_cnn.eval()\n","    correct_test = 0\n","    total_test = 0\n","\n","    with torch.no_grad():\n","        for data in test_loader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","\n","            outputs = simple_cnn(images)\n","            _, predicted = outputs.max(1)\n","            total_test += labels.size(0)\n","            correct_test += predicted.eq(labels).sum().item()\n","\n","    test_accuracy = 100 * correct_test / total_test\n","    print(f'Test Accuracy: {test_accuracy:.2f}%')\n","\n","print('Finished Training')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YM6pO1kzt3lY","executionInfo":{"status":"ok","timestamp":1703151302518,"user_tz":-210,"elapsed":188994,"user":{"displayName":"Pouria Dadkhah","userId":"05533946863193468432"}},"outputId":"e1ec651f-8b45-4996-e836-7929dc79ca38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|██████████| 782/782 [00:17<00:00, 45.61it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 1.4679, Training Accuracy: 46.94%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 54.39%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2: 100%|██████████| 782/782 [00:15<00:00, 49.86it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 1.0123, Training Accuracy: 64.21%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 65.98%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3: 100%|██████████| 782/782 [00:15<00:00, 49.61it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.7959, Training Accuracy: 72.32%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 71.59%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4: 100%|██████████| 782/782 [00:16<00:00, 48.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.6331, Training Accuracy: 77.91%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 70.54%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5: 100%|██████████| 782/782 [00:16<00:00, 48.74it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.4861, Training Accuracy: 82.96%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 75.31%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6: 100%|██████████| 782/782 [00:15<00:00, 49.80it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.3340, Training Accuracy: 88.55%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 75.11%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7: 100%|██████████| 782/782 [00:15<00:00, 48.98it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.2048, Training Accuracy: 93.14%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 74.72%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8: 100%|██████████| 782/782 [00:16<00:00, 48.36it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.1124, Training Accuracy: 96.43%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 74.38%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9: 100%|██████████| 782/782 [00:15<00:00, 49.65it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.0595, Training Accuracy: 98.15%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 75.85%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10: 100%|██████████| 782/782 [00:15<00:00, 49.70it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.0317, Training Accuracy: 99.16%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 75.16%\n","Finished Training\n"]}]},{"cell_type":"markdown","source":["Regularized simple cnn model"],"metadata":{"id":"utZLh6Pb56bi"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","# Define a simple CNN model with regularization and dropout\n","class RegularizedCNN(nn.Module):\n","    def __init__(self, dropout_rate=0.2, weight_decay=1e-5):\n","        super(RegularizedCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.fc2 = nn.Linear(512, 10)\n","\n","        # Add regularization to the weights\n","        self.weight_decay = weight_decay\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, m):\n","        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n","            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            if m.bias is not None:\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 128 * 8 * 8)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n","\n","# Instantiate the model, loss function, and optimizer with weight decay\n","regularized_cnn = RegularizedCNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(regularized_cnn.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n","\n","# Training the CNN with early stopping\n","num_epochs = 20\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","regularized_cnn.to(device)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n","\n","best_test_accuracy = 0.0\n","early_stopping_patience = 5\n","early_stopping_counter = 0\n","\n","for epoch in range(num_epochs):\n","    regularized_cnn.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","\n","    for data in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = regularized_cnn(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","        _, predicted = outputs.max(1)\n","        total_train += labels.size(0)\n","        correct_train += predicted.eq(labels).sum().item()\n","\n","    train_accuracy = 100 * correct_train / total_train\n","    print(f'Training Loss: {running_loss / len(train_loader):.4f}, Training Accuracy: {train_accuracy:.2f}%')\n","\n","    # Validation on the test set\n","    regularized_cnn.eval()\n","    correct_test = 0\n","    total_test = 0\n","\n","    with torch.no_grad():\n","        for data in test_loader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","\n","            outputs = regularized_cnn(images)\n","            _, predicted = outputs.max(1)\n","            total_test += labels.size(0)\n","            correct_test += predicted.eq(labels).sum().item()\n","\n","    test_accuracy = 100 * correct_test / total_test\n","    print(f'Test Accuracy: {test_accuracy:.2f}%')\n","\n","    # Early stopping based on validation accuracy\n","    if test_accuracy > best_test_accuracy:\n","        best_test_accuracy = test_accuracy\n","        early_stopping_counter = 0\n","    else:\n","        early_stopping_counter += 1\n","\n","    if early_stopping_counter >= early_stopping_patience:\n","        print(\"Early stopping! Test accuracy did not improve.\")\n","        break\n","\n","print('Finished Training')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQufYptJvQjM","executionInfo":{"status":"ok","timestamp":1703152511644,"user_tz":-210,"elapsed":338884,"user":{"displayName":"Pouria Dadkhah","userId":"05533946863193468432"}},"outputId":"d1a6fd65-a128-42ae-8823-7d1a2f3f572b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|██████████| 782/782 [00:15<00:00, 50.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 1.7435, Training Accuracy: 37.44%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 48.40%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2: 100%|██████████| 782/782 [00:16<00:00, 48.39it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 1.3770, Training Accuracy: 50.77%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 54.01%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3: 100%|██████████| 782/782 [00:17<00:00, 44.15it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 1.2284, Training Accuracy: 56.13%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 58.08%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4: 100%|██████████| 782/782 [00:16<00:00, 47.64it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 1.1215, Training Accuracy: 60.18%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 60.60%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5: 100%|██████████| 782/782 [00:15<00:00, 49.80it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 1.0341, Training Accuracy: 63.50%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 61.68%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6: 100%|██████████| 782/782 [00:15<00:00, 50.79it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.9499, Training Accuracy: 66.36%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 63.94%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7: 100%|██████████| 782/782 [00:16<00:00, 47.39it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.8706, Training Accuracy: 69.22%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 64.80%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8: 100%|██████████| 782/782 [00:15<00:00, 49.94it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.7960, Training Accuracy: 72.08%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 65.49%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9: 100%|██████████| 782/782 [00:15<00:00, 49.52it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.7341, Training Accuracy: 73.93%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 66.45%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10: 100%|██████████| 782/782 [00:16<00:00, 47.46it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.6738, Training Accuracy: 76.21%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 66.51%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11: 100%|██████████| 782/782 [00:15<00:00, 50.14it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.6080, Training Accuracy: 78.23%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 66.78%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12: 100%|██████████| 782/782 [00:15<00:00, 48.97it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.5546, Training Accuracy: 80.28%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 67.19%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13: 100%|██████████| 782/782 [00:16<00:00, 47.30it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.5068, Training Accuracy: 82.10%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 68.10%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14: 100%|██████████| 782/782 [00:15<00:00, 49.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.4609, Training Accuracy: 83.51%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 66.66%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15: 100%|██████████| 782/782 [00:15<00:00, 49.11it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.4246, Training Accuracy: 84.86%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 67.53%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16: 100%|██████████| 782/782 [00:16<00:00, 47.47it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.3822, Training Accuracy: 86.34%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 67.63%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17: 100%|██████████| 782/782 [00:15<00:00, 49.99it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.3563, Training Accuracy: 87.40%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 67.61%\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18: 100%|██████████| 782/782 [00:16<00:00, 47.63it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss: 0.3226, Training Accuracy: 88.57%\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 67.84%\n","Early stopping! Test accuracy did not improve.\n","Finished Training\n"]}]},{"cell_type":"markdown","source":["Deformable Network\n","\n","this part has some issues that have been fixed directely in the next session"],"metadata":{"id":"EaPb98COMBaH"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.ops as ops\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import time\n","import matplotlib.pyplot as plt\n","\n","class DeformableConv2d(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, deformable_groups=1):\n","        super(DeformableConv2d, self).__init__()\n","        self.conv_offset = nn.Conv2d(in_channels, deformable_groups * 2 * kernel_size * kernel_size, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.conv_weight = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.kernel_size = kernel_size\n","        self.deformable_groups = deformable_groups\n","\n","    def forward(self, x):\n","        offsets = self.conv_offset(x)\n","        weights = self.conv_weight(x)\n","\n","        # Ensure that the number of channels in the offset tensor is a multiple of 2 * weight.size[2] * weight.size[3]\n","        offset_channels = weights.size(2) * weights.size(3) * 2\n","        offsets = offsets[:, :offset_channels, :, :]\n","\n","        return ops.deform_conv2d(x, offsets, weights, self.kernel_size, padding=self.kernel_size // 2)\n","\n","class DeformableCNN(nn.Module):\n","    def __init__(self):\n","        super(DeformableCNN, self).__init__()\n","        self.conv1 = DeformableConv2d(3, 64, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = DeformableConv2d(64, 128, kernel_size=3, padding=1)\n","        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n","        self.fc2 = nn.Linear(512, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 128 * 8 * 8)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Training function for DeformableCNN\n","def train_deformable_cnn(model, train_loader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    correct_train = 0\n","    total_train = 0\n","    start_time = time.time()\n","\n","    for data in tqdm(train_loader, desc=\"Training\"):\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","        _, predicted = outputs.max(1)\n","        total_train += labels.size(0)\n","        correct_train += predicted.eq(labels).sum().item()\n","\n","    end_time = time.time()\n","    execution_time = end_time - start_time\n","    train_accuracy = 100 * correct_train / total_train\n","    avg_loss = running_loss / len(train_loader)\n","\n","    return avg_loss, train_accuracy, execution_time\n","\n","# Testing function for DeformableCNN\n","def test_deformable_cnn(model, test_loader, criterion, device):\n","    model.eval()\n","    correct_test = 0\n","    total_test = 0\n","    running_loss = 0.0\n","    start_time = time.time()\n","\n","    with torch.no_grad():\n","        for data in tqdm(test_loader, desc=\"Testing\"):\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            running_loss += loss.item()\n","\n","            _, predicted = outputs.max(1)\n","            total_test += labels.size(0)\n","            correct_test += predicted.eq(labels).sum().item()\n","\n","    end_time = time.time()\n","    execution_time = end_time - start_time\n","    test_accuracy = 100 * correct_test / total_test\n","    avg_loss = running_loss / len(test_loader)\n","\n","    return avg_loss, test_accuracy, execution_time\n","\n","# Instantiate the Deformable CNN model, loss function, and optimizer\n","deformable_cnn = DeformableCNN()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(deformable_cnn.parameters(), lr=0.01, momentum=0.9)\n","\n","# Move the model to the device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","deformable_cnn.to(device)\n","\n","# Data loaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n","\n","# Training and testing loop for DeformableCNN\n","num_epochs = 20\n","train_losses_deformable = []\n","train_accuracies_deformable = []\n","test_losses_deformable = []\n","test_accuracies_deformable = []\n","train_times_deformable = []\n","test_times_deformable = []\n","\n","for epoch in range(num_epochs):\n","    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n","\n","    # Training\n","    train_loss, train_accuracy, train_time = train_deformable_cnn(deformable_cnn, train_loader, criterion, optimizer, device)\n","    train_losses_deformable.append(train_loss)\n","    train_accuracies_deformable.append(train_accuracy)\n","    train_times_deformable.append(train_time)\n","\n","    # Testing\n","    test_loss, test_accuracy, test_time = test_deformable_cnn(deformable_cnn, test_loader, criterion, device)\n","    test_losses_deformable.append(test_loss)\n","    test_accuracies_deformable.append(test_accuracy)\n","    test_times_deformable.append(test_time)\n","\n","    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Train Time: {train_time:.2f}s\")\n","    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%, Test Time: {test_time:.2f}s\")\n","\n","# Plotting results for DeformableCNN\n","epochs_range = range(1, num_epochs + 1)\n","\n","plt.figure(figsize=(15, 5))\n","\n","# Plotting Accuracy\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, train_accuracies_deformable, label='Train Accuracy (Deformable)', marker='o')\n","plt.plot(epochs_range, test_accuracies_deformable, label='Test Accuracy (Deformable)', marker='o')\n","plt.title('Accuracy Over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy (%)')\n","plt.legend()\n","\n","# Plotting Loss\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, train_losses_deformable, label='Train Loss (Deformable)', marker='o')\n","plt.plot(epochs_range, test_losses_deformable, label='Test Loss (Deformable)', marker='o')\n","plt.title('Loss Over Epochs')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"id":"q3kQbeF99eZv","executionInfo":{"status":"error","timestamp":1703155588400,"user_tz":-210,"elapsed":360,"user":{"displayName":"Pouria Dadkhah","userId":"05533946863193468432"}},"outputId":"1d9ef09d-8573-440d-d8ed-d771f95b1961"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training:   0%|          | 0/782 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-8586b2c44351>\u001b[0m in \u001b[0;36m<cell line: 127>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_deformable_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeformable_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mtrain_losses_deformable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mtrain_accuracies_deformable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-8586b2c44351>\u001b[0m in \u001b[0;36mtrain_deformable_cnn\u001b[0;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-8586b2c44351>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-8586b2c44351>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0moffset_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeform_conv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDeformableCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/deform_conv.py\u001b[0m in \u001b[0;36mdeform_conv2d\u001b[0;34m(input, offset, weight, bias, stride, padding, dilation, mask)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_offset_grps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;34m\"the shape of the offset tensor at dimension 1 is not valid. It should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;34m\"be a multiple of 2 * weight.size[2] * weight.size[3].\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: the shape of the offset tensor at dimension 1 is not valid. It should be a multiple of 2 * weight.size[2] * weight.size[3].\nGot offset.shape[1]=18, while 2 * weight.size[2] * weight.size[3]=2048"]}]},{"cell_type":"markdown","source":["# Final models and Comparision results"],"metadata":{"id":"_yKa7QzLNgXZ"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import random\n","from torch import nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR\n","import torchvision.ops as ops\n","import time\n","\n","def setup_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    # torch.backends.cudnn.benchmark = True\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","class DeformableConv2d(nn.Module):\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 kernel_size=3,\n","                 stride=1,\n","                 padding=1,\n","                 bias=False):\n","\n","        super(DeformableConv2d, self).__init__()\n","\n","        self.padding = padding\n","\n","        self.offset_conv = nn.Conv2d(in_channels,\n","                                     2 * kernel_size * kernel_size,\n","                                     kernel_size=kernel_size,\n","                                     stride=stride,\n","                                     padding=self.padding,\n","                                     bias=True)\n","\n","        nn.init.constant_(self.offset_conv.weight, 0.)\n","        nn.init.constant_(self.offset_conv.bias, 0.)\n","\n","        self.modulator_conv = nn.Conv2d(in_channels,\n","                                     1 * kernel_size * kernel_size,\n","                                     kernel_size=kernel_size,\n","                                     stride=stride,\n","                                     padding=self.padding,\n","                                     bias=True)\n","\n","        nn.init.constant_(self.modulator_conv.weight, 0.)\n","        nn.init.constant_(self.modulator_conv.bias, 0.)\n","\n","        self.regular_conv = nn.Conv2d(in_channels=in_channels,\n","                                      out_channels=out_channels,\n","                                      kernel_size=kernel_size,\n","                                      stride=stride,\n","                                      padding=self.padding,\n","                                      bias=bias)\n","\n","    def forward(self, x):\n","        h, w = x.shape[2:]\n","        max_offset = max(h, w) / 4.\n","\n","        offset = self.offset_conv(x).clamp(-max_offset, max_offset)\n","        modulator = 2. * torch.sigmoid(self.modulator_conv(x))\n","\n","        x = ops.deform_conv2d(input=x,\n","                              offset=offset,\n","                              weight=self.regular_conv.weight,\n","                              bias=self.regular_conv.bias,\n","                              padding=self.padding,\n","                              mask=modulator\n","                              )\n","        return x\n","\n","class CIFAR10Classifier(nn.Module):\n","    def __init__(self, deformable=False):\n","        super(CIFAR10Classifier, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n","\n","        conv = nn.Conv2d if not deformable else DeformableConv2d\n","        self.conv4 = conv(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.conv5 = conv(32, 32, kernel_size=3, stride=1, padding=1, bias=True)\n","\n","        self.pool = nn.MaxPool2d(2)\n","        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(32, 10)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = torch.relu(self.conv2(x))\n","        x = self.pool(x)\n","        x = torch.relu(self.conv3(x))\n","        x = torch.relu(self.conv4(x))\n","        x = torch.relu(self.conv5(x))\n","        x = self.gap(x)\n","        x = x.flatten(start_dim=1)\n","        x = self.fc(x)\n","        return x\n","\n","def train(model, loss_function, device, train_loader, optimizer, epoch):\n","    model.train()\n","    start_time = time.time()\n","\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = loss_function(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","    end_time = time.time()\n","    execution_time = end_time - start_time\n","\n","    return execution_time\n","\n","def test(model, loss_function, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    num_data = 0\n","    start_time = time.time()\n","\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += loss_function(output, target).item()  # sum up batch mean loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","            num_data += len(data)\n","\n","    end_time = time.time()\n","    execution_time = end_time - start_time\n","\n","    test_loss /= num_data\n","    test_acc = 100. * correct / num_data\n","\n","    return test_acc, test_loss, execution_time\n","\n","def main(use_deformable_conv=False):\n","    # Training settings\n","    seed = 1\n","    setup_seed(seed)\n","\n","    use_cuda = torch.cuda.is_available()\n","    batch_size = 64\n","    lr = 1e-3\n","    gamma = 0.7\n","    epochs = 14\n","\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    train_kwargs = {'batch_size': batch_size}\n","    test_kwargs = {'batch_size': batch_size}\n","    if use_cuda:\n","        cuda_kwargs = {'num_workers': 4,\n","                       'pin_memory': True,\n","                       'shuffle': True}\n","        train_kwargs.update(cuda_kwargs)\n","        test_kwargs.update(cuda_kwargs)\n","\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","\n","    train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n","    test_dataset = datasets.CIFAR10('./data', train=False, transform=transform)\n","\n","    train_loader = torch.utils.data.DataLoader(train_dataset, **train_kwargs)\n","    test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)\n","\n","    model = CIFAR10Classifier(use_deformable_conv).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n","    loss_function = nn.CrossEntropyLoss()\n","    best_test_acc = 0.\n","\n","    # Initialize metrics\n","    # Initialize metrics\n","    train_acc, test_acc = 0.0, 0.0\n","    train_loss, test_loss = 0.0, 0.0\n","    train_execution_time, test_execution_time = 0.0, 0.0\n","\n","    # Train standard or deformable convolution network\n","    for epoch in range(1, epochs + 1):\n","        train_execution_time += train(model, loss_function, device, train_loader, optimizer, epoch)\n","        train_acc, train_loss = evaluate(model, loss_function, device, train_loader)\n","        test_acc, test_loss, test_time = test(model, loss_function, device, test_loader)\n","        test_execution_time += test_time\n","\n","        best_test_acc = max(best_test_acc, test_acc)\n","        scheduler.step()\n","\n","    # Report results\n","    print(\"Best Top-1 Accuracy (%): \", f\"{best_test_acc:.2f}\")\n","    print(\"Total Training Execution Time: {:.2f}s\".format(train_execution_time))\n","    print(\"Total Testing Execution Time: {:.2f}s\".format(test_execution_time))\n","\n","    return train_acc, test_acc, train_loss, test_loss, train_execution_time, test_execution_time\n","\n","# Add a new function for evaluation\n","def evaluate(model, loss_function, device, data_loader):\n","    model.eval()\n","    loss = 0.0\n","    correct = 0\n","    num_data = 0\n","\n","    with torch.no_grad():\n","        for data, target in data_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            loss += loss_function(output, target).item()  # sum up batch mean loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","            num_data += len(data)\n","\n","    loss /= num_data\n","    acc = 100. * correct / num_data\n","\n","    return acc, loss\n","\n","# Compare standard and deformable convolution networks\n","print(\"Standard Convolution:\")\n","train_acc_standard, test_acc_standard, train_loss_standard, test_loss_standard, train_time_standard, test_time_standard = main(use_deformable_conv=False)\n","\n","print(\"\\nDeformable Convolution:\")\n","train_acc_deformable, test_acc_deformable, train_loss_deformable, test_loss_deformable, train_time_deformable, test_time_deformable = main(use_deformable_conv=True)\n","\n","# Compare metrics\n","print(\"\\nComparison:\")\n","print(\"Train Accuracy - Standard: {:.2f}% | Deformable: {:.2f}%\".format(train_acc_standard, train_acc_deformable))\n","print(\"Test Accuracy - Standard: {:.2f}% | Deformable: {:.2f}%\".format(test_acc_standard, test_acc_deformable))\n","print(\"Train Loss - Standard: {:.4f} | Deformable: {:.4f}\".format(train_loss_standard, train_loss_deformable))\n","print(\"Test Loss - Standard: {:.4f} | Deformable: {:.4f}\".format(test_loss_standard, test_loss_deformable))\n","print(\"Train Execution Time - Standard: {:.2f}s | Deformable: {:.2f}s\".format(train_time_standard, train_time_deformable))\n","print(\"Test Execution Time - Standard: {:.2f}s | Deformable: {:.2f}s\".format(test_time_standard, test_time_deformable))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cW8lJjnBTPA","executionInfo":{"status":"ok","timestamp":1703359420771,"user_tz":-210,"elapsed":990558,"user":{"displayName":"Pouria Dadkhah","userId":"05533946863193468432"}},"outputId":"47e70243-2d22-409b-8a7f-9e9d180e6414"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Standard Convolution:\n","Files already downloaded and verified\n","Best Top-1 Accuracy (%):  61.31\n","Total Training Execution Time: 224.75s\n","Total Testing Execution Time: 43.90s\n","\n","Deformable Convolution:\n","Files already downloaded and verified\n","Best Top-1 Accuracy (%):  67.10\n","Total Training Execution Time: 253.78s\n","Total Testing Execution Time: 45.66s\n","\n","Comparison:\n","Train Accuracy - Standard: 62.01% | Deformable: 68.87%\n","Test Accuracy - Standard: 61.14% | Deformable: 67.10%\n","Train Loss - Standard: 0.0165 | Deformable: 0.0137\n","Test Loss - Standard: 0.0169 | Deformable: 0.0148\n","Train Execution Time - Standard: 224.75s | Deformable: 253.78s\n","Test Execution Time - Standard: 43.90s | Deformable: 45.66s\n"]}]},{"cell_type":"markdown","source":["As we saw in the result, the DCN model has better performance for train and test accuracy in the similiar context of implementations and takes just a negligible amount of time more than simple cnn!\n","\n","** actually the performance of models aren't good enough at all because of the simpleness of the models and doesn't configure the hyperparameters so well but the main concept of the question was comparing the dcn and cnn in the same situations to see the performance of them which we can see in this experiment as needed. by improving the models these results will get better both.**"],"metadata":{"id":"gb116nJbNsHN"}}]}