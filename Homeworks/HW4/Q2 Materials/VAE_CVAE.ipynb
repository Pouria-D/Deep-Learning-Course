{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTuaIdGJEqRc"
      },
      "source": [
        "<h1 style=\"text-align: center\">\n",
        "Deep Learning HW3 </br>\n",
        "VAE and CVAE\n",
        "</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5MiRbbuGbmA"
      },
      "source": [
        "### Full Name: ------\n",
        "### Student ID: ------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cWlBsdIJiV8"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Xls_DbtHydf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyoKovGiJo_U"
      },
      "source": [
        "# Define the MNIST dataset and data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-exgcL5Jkqb"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMD2yD-yJvXz"
      },
      "source": [
        "# Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxHAgFJfJx28"
      },
      "outputs": [],
      "source": [
        "# Function to display an image\n",
        "def show_image(image, figsize=(5, 5)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Function to show random images from each class\n",
        "def show_random_images_from_each_class(dataset, num_images_per_class=4, figsize=(10, 20)):\n",
        "    class_labels = list(range(10))  \n",
        "    fig, axs = plt.subplots(len(class_labels), num_images_per_class, figsize=figsize) \n",
        "\n",
        "    for i, label in enumerate(class_labels):\n",
        "        class_indices = [idx for idx, target in enumerate(dataset.targets) if target == label]\n",
        "        random_indices = random.sample(class_indices, num_images_per_class)\n",
        "\n",
        "        for j, idx in enumerate(random_indices):\n",
        "            image, target = dataset[idx]\n",
        "            axs[i, j].imshow(image[0], cmap='gray')\n",
        "            axs[i, j].set_title(f\"Class {label}\", fontsize=16)\n",
        "            axs[i, j].axis('off')\n",
        "            axs[i, j].set_aspect('equal')  \n",
        "            axs[i, j].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRWLPvTFJ2pS"
      },
      "outputs": [],
      "source": [
        "# Use the function to show random images from each class\n",
        "show_random_images_from_each_class(train_dataset, num_images_per_class=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FMl4JeoKDKL"
      },
      "source": [
        "Exercise: Variational Autoencoders (VAE) and Conditional Variational Autoencoders (CVAE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQrFJUXXKF9p"
      },
      "source": [
        "with MLP Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnpL-pw9KG0C"
      },
      "source": [
        "In this exercise, we'll explore Variational Autoencoders (VAE) and Conditional VAE (CVAE) using PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5HWQihDKJh6"
      },
      "source": [
        "We will implement these models using Multi-Layer Perceptrons (MLP) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm823PxKKL06"
      },
      "source": [
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjZJP48YKN5R"
      },
      "source": [
        "# 1) VAE --> MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtM6FO5cKSLr"
      },
      "outputs": [],
      "source": [
        "# Define a simple VAE class with MLP architecture\n",
        "\n",
        "class VAE_MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(VAE_MLP, self).__init__()\n",
        "        # TODO: Define the architecture of the encoder and decoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            # TODO: Add layers for the encoder\n",
        "        )\n",
        "        self.fc_mu = None\n",
        "        self.fc_logvar = None\n",
        "        self.decoder = nn.Sequential(\n",
        "            # TODO: Add layers for the decoder\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        # TODO: Implement the reparameterization trick\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Implement the forward pass\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpJi7irWLCMJ"
      },
      "outputs": [],
      "source": [
        "# Define VAE loss function\n",
        "\n",
        "def vae_loss(recon, data, mu, logvar):\n",
        "    # TODO: Implement the reconstruction loss\n",
        "    reconstruction_loss = None\n",
        "\n",
        "    # TODO: Implement the KL divergence loss\n",
        "    kl_divergence = None\n",
        "\n",
        "    # TODO: Return the total loss as the sum of reconstruction and KL divergence losses\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsOcJ986LU_R"
      },
      "outputs": [],
      "source": [
        "# Training Loop - VAE (MLP)\n",
        "def train_vae_mlp(model, train_loader, num_epochs=10, learning_rate=1e-3):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_loss = float('inf')  # Initialize with a high value\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print()\n",
        "        print(50 * \"#\")\n",
        "        total_loss = 0\n",
        "        for batch_idx, (data, _) in enumerate(train_loader):\n",
        "            # TODO: Forward process\n",
        "\n",
        "            # TODO: Flatten the data and recon tensors\n",
        "            data = None\n",
        "            recon = None\n",
        "\n",
        "            # TODO: Calculate the loss using the vae_loss function\n",
        "            loss = None\n",
        "\n",
        "            # TODO: Backpropagation and optimization step\n",
        "            None\n",
        "\n",
        "            total_loss = None\n",
        "\n",
        "        avg_loss = None\n",
        "        print(f'VAE-MLP Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss}')\n",
        "\n",
        "        # Show some sample images after each epoch\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            print(\"Sample Images:\")\n",
        "            with torch.no_grad():\n",
        "                num_samples = 6  # Generate num_samples random samples\n",
        "                sample = torch.randn(num_samples, 20)\n",
        "                sample = model.decoder(sample).view(num_samples, 1, 28, 28)\n",
        "                sample = sample.squeeze().cpu()\n",
        "                fig, axs = plt.subplots(1, num_samples, figsize=(15, 2))\n",
        "                for i in range(num_samples):\n",
        "                    axs[i].imshow(sample[i], cmap='gray')\n",
        "                    axs[i].axis('off')\n",
        "                plt.show()\n",
        "\n",
        "        # TODO: Save the best model based on loss\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model = None  # TODO: Save the model\n",
        "\n",
        "    # TODO: Save the best model to a file\n",
        "    None\n",
        "    print(\"Best model saved as 'best_vae_mlp_model.pth'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlKpLuOoLtdv"
      },
      "outputs": [],
      "source": [
        "# Train VAE-MLP\n",
        "vae_mlp = None\n",
        "train_vae_mlp(vae_mlp, train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI7KhUKoPOTt"
      },
      "source": [
        "# 2) CVAE --> MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0t8nce1PVmE"
      },
      "outputs": [],
      "source": [
        "# Define a simple CVAE class with MLP architecture\n",
        "\n",
        "class CVAE_MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim, num_classes):\n",
        "        super(CVAE_MLP, self).__init__()\n",
        "        # TODO: Define the architecture of the encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            # TODO: Add layers for the encoder\n",
        "        )\n",
        "        self.fc_mu = None\n",
        "        self.fc_logvar = None\n",
        "        self.fc_class = None\n",
        "\n",
        "        # TODO: Define the architecture of the decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            # TODO: Add layers for the decoder\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        # TODO: Implement the reparameterization trick\n",
        "        pass\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        y = y.view(y.size(0), -1)\n",
        "\n",
        "        # TODO: Concatenate x and y before passing them to the encoder\n",
        "        x = None\n",
        "\n",
        "        # TODO: Implement the forward pass\n",
        "        hidden = None\n",
        "        mu = None\n",
        "        logvar = None\n",
        "        z = None\n",
        "        class_logits = None\n",
        "\n",
        "        reconstructed = None\n",
        "\n",
        "        return reconstructed, mu, logvar, class_logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3xHfeQPhUB2"
      },
      "outputs": [],
      "source": [
        "# Define CVAE loss function\n",
        "def cvae_loss(recon, data, mu, logvar, class_logits, labels):\n",
        "    # TODO: Flatten the data tensor\n",
        "    data = None\n",
        "\n",
        "    # TODO: Implement the reconstruction loss\n",
        "    reconstruction_loss = None\n",
        "\n",
        "    # TODO: Implement the KL divergence loss\n",
        "    kl_divergence = None\n",
        "\n",
        "    # TODO: Implement the cross-entropy loss for class prediction\n",
        "    ce_loss = None\n",
        "\n",
        "    # TODO: Return the total loss as the sum of reconstruction, KL divergence, and cross-entropy losses\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hYPGDSQhU99"
      },
      "outputs": [],
      "source": [
        "# Training Loop - CVAE (MLP)\n",
        "def train_cvae_mlp(model, train_loader, num_epochs=10, learning_rate=1e-3):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_loss = float('inf')  # Initialize with a high value\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print()\n",
        "        print(50 * \"#\")\n",
        "        total_loss = 0\n",
        "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            # One-hot encode the labels\n",
        "            labels_one_hot = None\n",
        "\n",
        "            # TODO: Forward pass through the model and calculate the loss using cvae_loss\n",
        "            recon = None\n",
        "            mu = None\n",
        "            logvar = None\n",
        "            class_logits = None\n",
        "            loss = None\n",
        "\n",
        "            # TODO: Backpropagation and optimization step\n",
        "            None\n",
        "\n",
        "            total_loss = None\n",
        "\n",
        "        avg_loss = None\n",
        "        print(f'CVAE-MLP Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss}')\n",
        "\n",
        "        # Show some sample images after each epoch\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            print(\"Sample Images:\")\n",
        "            with torch.no_grad():\n",
        "                num_classes = 10  # Number of classes (0 to 9)\n",
        "                num_samples_per_class = 1  # One sample per class\n",
        "                # Generate random samples\n",
        "                z = torch.randn(num_classes * num_samples_per_class, 20)\n",
        "                # Generate one-hot encoded class labels\n",
        "                y = torch.eye(num_classes).repeat(num_samples_per_class, 1)\n",
        "                # Concatenate the random samples and class labels before passing them to the decoder\n",
        "                sample = torch.cat([z, y], dim=1)\n",
        "                sample = model.decoder(sample).view(num_classes * num_samples_per_class, 1, 28, 28)\n",
        "                sample = sample.squeeze().cpu()\n",
        "                fig, axs = plt.subplots(1, num_classes, figsize=(15, 2))\n",
        "                for i in range(num_classes):\n",
        "                    axs[i].imshow(sample[i], cmap='gray')\n",
        "                    axs[i].set_title(f\"Class {i}\", fontsize=16)\n",
        "                    axs[i].axis('off')\n",
        "                plt.show()\n",
        "\n",
        "        # TODO: Save the best model based on loss\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            best_model = None\n",
        "\n",
        "    # TODO: Save the best model to a file\n",
        "    None\n",
        "    print(\"Best model saved as 'best_cvae_mlp_model.pth'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d7Q-iqjiVDc"
      },
      "outputs": [],
      "source": [
        "cvae_mlp = None\n",
        "train_cvae_mlp(cvae_mlp, train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYB4Id3VPxDF"
      },
      "source": [
        "# 3) Visualizing Latent Space Distribution in Two Models\n",
        "\n",
        "In this section, we will visualize the latent space distribution for two different models:\n",
        "\n",
        "## Latent Space Distribution:\n",
        "\n",
        "### VAE (MLP):\n",
        "\n",
        "1. Visualize the latent space distribution using Multilayer Perceptron (MLP) in VAE model.\n",
        "2. Analyze the characteristics of the distribution.\n",
        "\n",
        "### CVAE (MLP):\n",
        "\n",
        "1. Visualize the latent space distribution using Multilayer Perceptron (MLP) in CVAE model.\n",
        "2. Analyze the characteristics of the distribution.\n",
        "\n",
        "\n",
        "Summarize your findings and draw conclusions based on the observed differences in the latent space distribution between VAE (MLP) and CVAE (MLP).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGYNnqb4DbIk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HrN7YznE8Ih"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
